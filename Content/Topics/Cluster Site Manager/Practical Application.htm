<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" xml:lang="en-us" MadCap:lastBlockDepth="10" MadCap:lastHeight="1712" MadCap:lastWidth="1064">
    <head><title></title>
    </head>
    <body>
        <h1>Practical Application</h1>
        <p>One of the most common points of contention in the clustering process is simply determining which clustering algorithm – K-Means or K-Medoids – will yield the most accurate results. This decision really depends on the nature of the specific data being used to calculate the desired cluster sets. Here are a few things to consider when making this decision:</p>
        <ul>
            <li><b>Performance</b>: the K-Means algorithm requires far fewer iterations to resolve than K-Medoids does, which means reduced time required to calculate (and re-calculate) cluster sets created via this method. If your business requires a large number of cluster sets and/or those cluster sets need to be updated frequently, this may be a point of differentiation when making your choice</li>
            <li><b>Data Anomalies</b>: the K-Medoids algorithm is generally considered to be more responsive to data with a high degree of noise and/or outliers than K-Means. Whether K-Medoids will produce a more accurate result than K-Means is entirely dependent on the data returned by the criteria you specify. To illustrate this point, see the example* below:</li>
        </ul>
        <p>
            <img src="../../Resources/Images/Cluster Site Manager/Practical Application.png" />
        </p>
        <p>* The illustration was prepared with the Java applet, E.M. Mirkes,&#160;<a href="http://www.math.le.ac.uk/people/ag153/homepage/KmeansKmedoids/Kmeans_Kmedoids.html">K-means and K-medoids: applet</a>. University of Leicester, 2011</p>
        <p>Figures 1a) – 1f) depict the iterations of the K-Means algorithm on a particular data set, where figures 2a) – 2h) depict the iterations of the K-Medoids algorithm on the same set; notice that, in this case, K-Means has ignored the clear differentiation of the two groups in the lower half of the grid, whereas K-Medoids provided what appears to be the more accurate solution</p>
        <p>This occurred largely due to the fact that K-Means estimates the ideal positioning of arbitrary centroids to define clusters whereas K-Medoids uses actual data points in the set as medoids to define its clusters. Not every data set will have such a clear-cut differentiation of groups, though, and users should be aware that, in some cases, the accuracy of one method over the other may be somewhat subjective</p>
        <p class="important" MadCap:autonum="&lt;b&gt;IMPORTANT: &lt;/b&gt;">Proper structuring of cluster sets is essential to getting the most out of the Assortment Planning module. Before you begin creating cluster sets for use with Assortment Planning, make sure you’ve read the introduction to Cluster Set Management, as well as the Prerequisites and Essential Business Concepts and have completed the steps described therein. Once you’ve done this, creating the ideal cluster sets for your business really comes down to two questions:</p>
        <ul>
            <li>At what level of our business is there the greatest variation in performance among stores?<ul><li>The best way to gain a proper understanding of this is by analyzing how your stores rank with your selected criteria at multiple levels:<ul><li>Create several groups of cluster sets, perhaps starting as high as total company for all products and stores, and building out groups all the way down to the lowest proposed level – use the same Classification and Attribute Settings for each group</li></ul><ul><li>Compare the store rankings for each subsequent cluster set to the top level set; there are a number of ways to achieve this but the focus of the analysis is essentially to compare how different the lower level results are against the top level results and determine if the variation at each level is significant enough to warrant the additional complexity; some examples of how to approach this are:<ul><li>By store, calculate the number of cluster sets at each level that assign that store to each classification, sum the cluster sets whose classification assignment deviates from the top level assignment, then compare each level by sum or average deviations to identify the level at which additional complexity ceases to cause significant increase</li></ul><ul><li>Calculate the number of deviations in classification assignment from the top level by store for each cluster set level and compare each level by sum or average deviations to identify the level at which additional complexity ceases to cause significant increase</li></ul><ul><li><p class="warning" MadCap:autonum="&lt;b&gt;WARNING: &lt;/b&gt;">when using the sum of deviations by level, depending on the nature of the underlying data used in calculation of your cluster sets, the tendency is for lower levels to yield greater sums simply because of the increase in the number of cluster sets</p></li></ul></li></ul></li></ul></li>
        </ul>
        <ul>
            <li>Can our organization handle planning at this level of detail without significant impact to our current ordering timelines?<ul><li>Once you’ve answered the first question, you now need to understand if your team can realistically support analyzing at that level of detail:<ul><li>Group the number of proposed cluster sets into areas that could be managed by a single individual</li></ul><ul><li>If this number is greater than the number of people on your team, you need to weigh the perceived benefit of planning at the proposed level against the cost of hiring more personnel</li></ul><ul><li>If the cost of changing your team to suit the greater level of detail is greater than the expected return, compromise by examining the other levels in your analysis and identifying one that is feasible </li></ul></li></ul></li>
        </ul>
    </body>
</html>